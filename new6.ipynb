{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "355a3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from IPython.display import display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db6e276c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import LeakyReLU \n",
    "from tensorflow.keras.layers import Flatten, Conv2D, AveragePooling2D, MaxPooling2D, Dropout\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "# Layer-1 Convolution  application des filtres , 96 filtres ,11x11 taille filtre , fct d'activation relu , 1x1 couche s'applique sur chaque pixel\n",
    "classifier.add(Conv2D(96,(11,11),strides=(4,4), input_shape = (150,220,3), activation = 'relu'))\n",
    "\n",
    "# Layer-2 Pooling reduire taille des images, choisir max\n",
    "classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "# Layer-3 Convolution , zeropadding :Cette couche peut ajouter des lignes et des colonnes de zéros en haut, en bas, à gauche et à droite d'un tenseur d'image.\n",
    "classifier.add(ZeroPadding2D(padding=(2, 2)))\n",
    "classifier.add(Conv2D(256,(5,5),strides=(2,2), activation = 'relu'))\n",
    "\n",
    "# Layer-4 Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (3,3)))\n",
    "\n",
    "# Layer-5 Convolution\n",
    "classifier.add(ZeroPadding2D(padding=(1, 1)))\n",
    "classifier.add(Conv2D(384,(3,3),strides=(1,1), activation = 'relu'))\n",
    "\n",
    "# Layer-6 Convolution\n",
    "classifier.add(ZeroPadding2D(padding=(1, 1)))\n",
    "classifier.add(Conv2D(384,(3,3),strides=(1,1), activation = 'relu'))\n",
    "\n",
    "# Layer-7 Convolution\n",
    "classifier.add(ZeroPadding2D(padding=(1, 1)))\n",
    "classifier.add(Conv2D(256,(3,3),strides=(1,1), activation = 'relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "\n",
    "# Layer-9 Flattening , matrice devient tableau\n",
    "classifier.add(Flatten())\n",
    "#relu remplacer les résultats négatifs par zéro.\n",
    "#Sigmoïde donne une valeur entre 0 et 1, une probabilité. Elle est donc très utilisée pour les classification binaire, lorsqu’un modèle doit déterminer seulement deux labels.\n",
    "# Layer-10 Full Connection\n",
    "classifier.add(Dense(units =512, activation = \"relu\"))\n",
    "classifier.add(Dense(units = 64, activation = \"relu\"))\n",
    "classifier.add(Dropout(0.5))\n",
    "#dropout éviter overfitting  désactive temporairement certains neurones dans le réseau, ainsi que toutes ses connexions entrantes et sortantes \n",
    "classifier.add(Dense(units = 1, activation = \"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96f5cdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "730274f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36bcbd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d793d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1712 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('dataset', target_size = (150, 220), batch_size = 16, class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f85bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 300 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('sample_Signature', target_size = (150, 220), batch_size = 16, class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f237ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "107/107 [==============================] - 21s 192ms/step - loss: 0.7240 - accuracy: 0.5537 - val_loss: 0.6934 - val_accuracy: 0.5000\n",
      "Epoch 2/40\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 0.6894 - accuracy: 0.5532 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 3/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.6871 - accuracy: 0.5596 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 4/40\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.6877 - accuracy: 0.5596 - val_loss: 0.6962 - val_accuracy: 0.5000\n",
      "Epoch 5/40\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.6876 - accuracy: 0.5596 - val_loss: 0.6990 - val_accuracy: 0.5000\n",
      "Epoch 6/40\n",
      "107/107 [==============================] - 21s 197ms/step - loss: 0.6864 - accuracy: 0.5596 - val_loss: 0.7001 - val_accuracy: 0.5000\n",
      "Epoch 7/40\n",
      "107/107 [==============================] - 21s 196ms/step - loss: 0.6876 - accuracy: 0.5596 - val_loss: 0.6980 - val_accuracy: 0.5000\n",
      "Epoch 8/40\n",
      "107/107 [==============================] - 21s 198ms/step - loss: 0.6866 - accuracy: 0.5596 - val_loss: 0.7001 - val_accuracy: 0.5000\n",
      "Epoch 9/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6862 - accuracy: 0.5596 - val_loss: 0.7001 - val_accuracy: 0.5000\n",
      "Epoch 10/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6864 - accuracy: 0.5596 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 11/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6868 - accuracy: 0.5596 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
      "Epoch 12/40\n",
      "107/107 [==============================] - 21s 199ms/step - loss: 0.6871 - accuracy: 0.5596 - val_loss: 0.6981 - val_accuracy: 0.5000\n",
      "Epoch 13/40\n",
      "107/107 [==============================] - 22s 208ms/step - loss: 0.6859 - accuracy: 0.5596 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 14/40\n",
      "107/107 [==============================] - 22s 205ms/step - loss: 0.6867 - accuracy: 0.5596 - val_loss: 0.6988 - val_accuracy: 0.5000\n",
      "Epoch 15/40\n",
      "107/107 [==============================] - 22s 207ms/step - loss: 0.6846 - accuracy: 0.5596 - val_loss: 0.7009 - val_accuracy: 0.5000\n",
      "Epoch 16/40\n",
      "107/107 [==============================] - 24s 221ms/step - loss: 0.6857 - accuracy: 0.5596 - val_loss: 0.7016 - val_accuracy: 0.5000\n",
      "Epoch 17/40\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.6871 - accuracy: 0.5596 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
      "Epoch 18/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6863 - accuracy: 0.5596 - val_loss: 0.6998 - val_accuracy: 0.5000\n",
      "Epoch 19/40\n",
      "107/107 [==============================] - 22s 201ms/step - loss: 0.6869 - accuracy: 0.5596 - val_loss: 0.7004 - val_accuracy: 0.5000\n",
      "Epoch 20/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6864 - accuracy: 0.5596 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
      "Epoch 21/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6869 - accuracy: 0.5596 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
      "Epoch 22/40\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.6856 - accuracy: 0.5596 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
      "Epoch 23/40\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.6861 - accuracy: 0.5596 - val_loss: 0.7002 - val_accuracy: 0.5000\n",
      "Epoch 24/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6868 - accuracy: 0.5596 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 25/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6865 - accuracy: 0.5596 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
      "Epoch 26/40\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.6865 - accuracy: 0.5596 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
      "Epoch 27/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6856 - accuracy: 0.5596 - val_loss: 0.7005 - val_accuracy: 0.5000\n",
      "Epoch 28/40\n",
      "107/107 [==============================] - 21s 201ms/step - loss: 0.6871 - accuracy: 0.5596 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
      "Epoch 29/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6860 - accuracy: 0.5596 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
      "Epoch 30/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6863 - accuracy: 0.5596 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
      "Epoch 31/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6868 - accuracy: 0.5596 - val_loss: 0.6987 - val_accuracy: 0.5000\n",
      "Epoch 32/40\n",
      "107/107 [==============================] - 22s 201ms/step - loss: 0.6869 - accuracy: 0.5596 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
      "Epoch 33/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6864 - accuracy: 0.5596 - val_loss: 0.6989 - val_accuracy: 0.5000\n",
      "Epoch 34/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6870 - accuracy: 0.5596 - val_loss: 0.6984 - val_accuracy: 0.5000\n",
      "Epoch 35/40\n",
      "107/107 [==============================] - 22s 201ms/step - loss: 0.6861 - accuracy: 0.5596 - val_loss: 0.6993 - val_accuracy: 0.5000\n",
      "Epoch 36/40\n",
      "107/107 [==============================] - 22s 203ms/step - loss: 0.6857 - accuracy: 0.5596 - val_loss: 0.7002 - val_accuracy: 0.5000\n",
      "Epoch 37/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6851 - accuracy: 0.5596 - val_loss: 0.7008 - val_accuracy: 0.5000\n",
      "Epoch 38/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6857 - accuracy: 0.5596 - val_loss: 0.7009 - val_accuracy: 0.5000\n",
      "Epoch 39/40\n",
      "107/107 [==============================] - 22s 202ms/step - loss: 0.6863 - accuracy: 0.5596 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 40/40\n",
      "107/107 [==============================] - 21s 200ms/step - loss: 0.6865 - accuracy: 0.5596 - val_loss: 0.6996 - val_accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cbc0cffdf0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(training_set,epochs = 40,steps_per_epoch = len(training_set), validation_data = test_set, validation_steps =  len(test_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b758ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 2s 114ms/step - loss: 0.6996 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "validation_set_accuracy=classifier.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7665e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"m3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d251a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Accuracy is :  50.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation Set Accuracy is : \", validation_set_accuracy[1]*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
